{"metadata":{"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Train a multilingual xlm-roberta for text embedding through Siamese net and Triplet Loss in Pytorch","metadata":{}},{"cell_type":"code","source":"!ls ../input/shopee-product-matching/\n!ls ../input/shopee-generate-data-for-triplet-loss/train_triplets_titles.csv","metadata":{"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"sample_submission.csv  test.csv  test_images  train.csv  train_images\n../input/shopee-generate-data-for-triplet-loss/train_triplets_titles.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# import sys\n# sys.path.append ('/kaggle/input/pytorch-images-seresnet')\nimport os\nimport gc\nimport time\nimport math\nimport random\nimport datetime\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nfrom   torch.nn import init\nfrom   torch.nn import CrossEntropyLoss, MSELoss\nfrom   torch.nn.modules.loss import _WeightedLoss\nimport torch.nn.functional as F\nfrom   torch.nn import Parameter\nfrom   torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\nfrom   transformers import AdamW, get_cosine_schedule_with_warmup\nfrom   torch.cuda.amp import autocast, GradScaler\n\nfrom   transformers import BertForSequenceClassification, BertConfig, AutoTokenizer, AutoModelForSequenceClassification\nfrom   transformers import RobertaTokenizer, RobertaForSequenceClassification, XLMRobertaModel\n\nfrom   sklearn.model_selection import StratifiedKFold, GroupKFold\n# import timm\n\nimport albumentations as A\nfrom   albumentations import *\nfrom   albumentations.pytorch import ToTensorV2\nfrom   albumentations.core.transforms_interface import DualTransform\nfrom   albumentations.augmentations import functional as AF\nimport cv2\n\nfrom   tqdm import tqdm\nfrom   pprint import pprint\nfrom   functools import partial\nimport matplotlib.pyplot as plt\n# from GPUtil import showUtilization as gpu_usage\n# from   numba import cuda\nimport warnings\nwarnings.filterwarnings (\"ignore\")","metadata":{"papermill":{"duration":6.115871,"end_time":"2021-03-29T06:13:02.423924","exception":false,"start_time":"2021-03-29T06:12:56.308053","status":"completed"},"tags":[],"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    device       = torch.device ('cuda' if torch.cuda.is_available () else 'cpu')\n    num_workers  = 8\n    model_name   = 'xlmroberta'        # ['deit_base_patch16_224', 'vit_base_patch16_384', 'resnext50_32x4d', 'tf_efficientnet_b7_ns']\n    margin       = 1.0\n    size         = 128\n    isTrain      = True\n    isFreeze     = True\n    lr           = 1e-4\n    epochs       = 6\n    warmup_steps = 0.50                    # if float: these many epochs are with frozen model at the beginning, if int = actual steps\n    lr_num_cycles= 0.5\n    epochsNx     = 1\n    weight_decay = 1e-6\n    max_grad_norm= 1000.0\n    seed         = 42\n    n_fold       = 10\n    train_fold   = [0]                      # [0, 1, 2, 3, 4]\n    print_every  = 100\n    adam_epsilon = 1e-8\n    train_batch_size = 12\n    eval_batch_size  = 112\n    img_ext          = '.png'\n    img_col          = \"image_id\"\n    raw_label_cols   = 'class_id'\n    label_cols       = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n    target_size      = len (label_cols)\n    model_infer_path_prefix = \".\"\n    model_train_path_prefix = \".\"\n    text_triplets_csv= \"../input/shopee-generate-data-for-triplet-loss/train_triplets_titles.csv\"\n    train_path       = '../input/shopee-product-matching/train_images'\n    # train_csv        = '../input/vinbigdata-chest-xray-abnormalities-detection/train.csv'\n    # test_path        = '../input/vinbigdata-chest-xray-resized-png-1024x1024/test'\n    output_dir       = './results'        # output directory    \n    eval_steps       = 0.5                # if float: these many epochs are with frozen model at the beginning, if int = actual steps \n    max_steps        = 0\n    MODEL            = None","metadata":{"papermill":{"duration":0.051644,"end_time":"2021-03-29T06:13:02.512003","exception":false,"start_time":"2021-03-29T06:13:02.460359","status":"completed"},"tags":[],"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def init_logger (log_file=CFG.output_dir+'train.log'):\n    \n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger (__name__)\n    logger.setLevel (INFO)\n    handler1 = StreamHandler ()\n    handler1.setFormatter (Formatter (\"%(message)s\"))\n    handler2 = FileHandler (filename=log_file)\n    handler2.setFormatter (Formatter (\"%(message)s\"))\n    logger.addHandler (handler1)\n    logger.addHandler (handler2)\n    return logger","metadata":{"papermill":{"duration":0.046379,"end_time":"2021-03-29T06:13:02.594867","exception":false,"start_time":"2021-03-29T06:13:02.548488","status":"completed"},"tags":[],"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def seed_everything (seed):\n    \n    random.seed (seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed (seed)\n    torch.manual_seed (seed)\n    torch.cuda.manual_seed (seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    return","metadata":{"papermill":{"duration":0.047319,"end_time":"2021-03-29T06:13:02.67797","exception":false,"start_time":"2021-03-29T06:13:02.630651","status":"completed"},"tags":[],"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"# see image triplets\ndf = pd.read_csv (CFG.text_triplets_csv)\nTRAIN_DF = df.iloc[:(df.shape[0]*9//10)]\nTEST_DF  = df.iloc[(df.shape[0]*9//10):]\ndel df\ngc.collect ()\nTEST_DF.head ()","metadata":{"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                  anchor  \\\n30825  TOTEBAG KPOP PAKAI RESLETING / TOTE BAG KPOP /...   \n30826  Stroller Koper Cabin Size Kereta Dorong Bayi B...   \n30827                           Dakron isi Boneka 100grm   \n30828      Cussons Baby Hair and Body Wash 100ml + 100ml   \n30829                           Cokelat SNICKERS 35 Gram   \n\n                                                positive  \\\n30825  RESLETING TAS TOTE TOTEBAG KPOP / TOTE BAG KPO...   \n30826  Dorongan kereta bayi stroller BabyDoes Pronto ...   \n30827                   Dakron Super 100 gram/isi boneka   \n30828    Cussons Baby Hair & Body Wash Mild Gentle 200ml   \n30829        Coklat SNICKERS 35gr import Inggris PROMO!!   \n\n                                                negative  \n30825      [BPOM] Cosrx Clear Fit Master Patch isi 18pcs  \n30826        Masker Gelatin Organic 10 Gram by Poupeepou  \n30827  Lakban Besar OPP Isolasi Selotip TEBAL EKA TAP...  \n30828                         Stelan baju tidur 3in1~ XL  \n30829  Sendok Makan Bayi dan Anak Motif Tangan Mickey...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>anchor</th>\n      <th>positive</th>\n      <th>negative</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>30825</th>\n      <td>TOTEBAG KPOP PAKAI RESLETING / TOTE BAG KPOP /...</td>\n      <td>RESLETING TAS TOTE TOTEBAG KPOP / TOTE BAG KPO...</td>\n      <td>[BPOM] Cosrx Clear Fit Master Patch isi 18pcs</td>\n    </tr>\n    <tr>\n      <th>30826</th>\n      <td>Stroller Koper Cabin Size Kereta Dorong Bayi B...</td>\n      <td>Dorongan kereta bayi stroller BabyDoes Pronto ...</td>\n      <td>Masker Gelatin Organic 10 Gram by Poupeepou</td>\n    </tr>\n    <tr>\n      <th>30827</th>\n      <td>Dakron isi Boneka 100grm</td>\n      <td>Dakron Super 100 gram/isi boneka</td>\n      <td>Lakban Besar OPP Isolasi Selotip TEBAL EKA TAP...</td>\n    </tr>\n    <tr>\n      <th>30828</th>\n      <td>Cussons Baby Hair and Body Wash 100ml + 100ml</td>\n      <td>Cussons Baby Hair &amp; Body Wash Mild Gentle 200ml</td>\n      <td>Stelan baju tidur 3in1~ XL</td>\n    </tr>\n    <tr>\n      <th>30829</th>\n      <td>Cokelat SNICKERS 35 Gram</td>\n      <td>Coklat SNICKERS 35gr import Inggris PROMO!!</td>\n      <td>Sendok Makan Bayi dan Anak Motif Tangan Mickey...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Xlm-Roberta","metadata":{"papermill":{"duration":0.050835,"end_time":"2021-03-29T06:13:08.542138","exception":false,"start_time":"2021-03-29T06:13:08.491303","status":"completed"},"tags":[]}},{"cell_type":"code","source":"bert_model_name = 'xlm-roberta-large'\nmax_len         = CFG.size\ntokenizer       = AutoTokenizer.from_pretrained (bert_model_name)","metadata":{"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/513 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b73d7cd864b94559bf9c39311b6e3fb1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f463cd8761b04169886d76f55ed183aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca291cc26eb04f23b8a8c115e67cf5b0"}},"metadata":{}}]},{"cell_type":"code","source":"def encode (premise):\n    \n    encoded_dict = tokenizer (\n        premise,                   # 1st of the Sentence pair to encode.\n        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n        truncation=True,           # just max_len will not automatically truncate\n        max_length = max_len,      # Pad & truncate all sentences.\n        padding='max_length',\n        return_attention_mask = True,   # Construct attn. masks.\n        return_tensors = 'pt',     # Return pytorch tensors.\n    ) \n    # print ('encoded_dict =', encoded_dict)\n    # 1-D tensors are expected for a sample. Hence squeeze these 2-D tensors e.g [1,256] shaped tensors to 1-D [256] shape \n    for k in encoded_dict:\n        encoded_dict[k] = torch.squeeze (encoded_dict[k])\n    return encoded_dict","metadata":{"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class TripletTextDataset (Dataset):\n    \n    def __init__(self, df=TRAIN_DF):\n        self.df = df   # pd.read_csv (img_triplets_csv).reset_index (drop=True)\n        return\n    \n    def __getitem__(self, index):\n        \n        triplet  = self.df.iloc[index]\n        anchor   = triplet['anchor']\n        positive = triplet['positive']\n        negative = triplet['negative']\n        \n        anchor   = encode (anchor)\n        positive = encode (positive)\n        negative = encode (negative)\n        return (anchor, positive, negative)\n    \n    def __len__(self):\n        return self.df.shape[0]","metadata":{"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def plot_txt (dataset_show):\n        \n    for i in range (2):\n            idx = np.random.randint (0, len (dataset_show))\n            dict1, dict2, dict3 = dataset_show[idx] \n            print ('Anchor =',  dict1)\n            print ('+ve = ', dict2)\n            print ('-ve = ', dict3)\n    return \n\nTR_DATASET = TripletTextDataset ()\nplot_txt (TR_DATASET)\ndel TR_DATASET\ngc.collect ()","metadata":{"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Anchor = {'input_ids': tensor([     0,   5140,   5877,  30463,   7115, 165964,      2,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0])}\n+ve =  {'input_ids': tensor([     0, 169172,   9902,  55766, 120148,  30463,   7237,  14216, 177867,\n         23687, 197137,  45797,  98335,   5419,  88868,    919,  15567,  38586,\n        109592,    571, 199805,    841,   8992,  13940,    335,  12971, 105778,\n             6,  81218,  60148,  62562,  63587,  11183,  70080,      2,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0])}\n-ve =  {'input_ids': tensor([     0,  29227,  20113,    619,    159,  65441, 109003,      6, 116199,\n           619,    335, 181668,  22215,  35213,    248,  24291,  39456,    248,\n         16999,  13933,      6, 210851,      2,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0])}\nAnchor = {'input_ids': tensor([     0, 169172,  23490,    248,  33965,  33533,     14, 126074,  36795,\n          1603,  43609,   5390,    425,   5955,    619,    805,    425,   5955,\n            20,   2501,   7737, 148913,  20405,    619,  11399,  25922,      2,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0])}\n+ve =  {'input_ids': tensor([     0,  33533,     14, 126074,  36795,   1603,  43609,   5390,    425,\n          5955,    619,    805,    425,   5955,     20,   2356,  44965,      2,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0])}\n-ve =  {'input_ids': tensor([     0,    335,  36256,   8678, 113225,   5419,  94885,  65135,     38,\n        141034,  55126,      6,  41020,  73686,   9960,    670,      6, 130747,\n         25795,      6,  43789,  28751,  81178,      6, 130747,  25795,  21253,\n         46754,  23186,     62,  48952,  16312,    441,  70087,   8922, 121300,\n         85053,  20345,      2,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0])}\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"102"},"metadata":{}}]},{"cell_type":"markdown","source":"> # Loss Functions","metadata":{"papermill":{"duration":0.052832,"end_time":"2021-03-29T06:13:08.081563","exception":false,"start_time":"2021-03-29T06:13:08.028731","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def get_criterion (margin):\n    \n    criterion = nn.MarginRankingLoss (margin=margin)\n    return criterion","metadata":{"papermill":{"duration":0.062338,"end_time":"2021-03-29T06:13:08.439577","exception":false,"start_time":"2021-03-29T06:13:08.377239","status":"completed"},"tags":[],"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class MyGAPModelForSeqClf (nn.Module):\n    \n    def __init__(self, bert_model_name, outputCount=3, drop_prob=0.1, nonlin=nn.ReLU ()):\n        \n        super (MyGAPModelForSeqClf, self).__init__()\n        self.model       = AutoModelForSequenceClassification.from_pretrained (bert_model_name).base_model  # adding .base_model if using pretrained XLMRobertaForSequenceClassification\n        self.drop_prob   = drop_prob\n        self.nonlin      = nonlin\n        self.outputCount = outputCount\n        hidden_size      = self.model.config.hidden_size\n        self.dense       = nn.Linear (hidden_size, hidden_size)\n        self.batchnorm   = nn.BatchNorm1d (hidden_size)          # Not Used\n        self.outDense    = nn.Linear (hidden_size, outputCount)  # Not Used\n        self.dropout     = nn.Dropout (drop_prob)                # Not Used\n        self.outActivtn  = nn.LogSoftmax (dim=1)                 # Not Used\n        self.NLLLoss     = nn.NLLLoss ()                         # Not Used\n        return\n    \n    def freeze (self):\n        \n        for param in self.model.base_model.parameters ():\n            param.requires_grad = False\n        for param in self.dense.parameters ():\n            param.requires_grad = True\n        return\n    \n    def unfreeze (self):\n        \n        for param in self.model.base_model.parameters ():\n            param.requires_grad = True\n        for param in self.dense.parameters ():\n            param.requires_grad = True\n        return\n    \n    def forward (self, input_ids, attention_mask, token_type_ids=None, labels=None, **kwargs):\n        \n        last_hidden_states = None\n        \n        # The base bert model do not take labels as input\n        if token_type_ids is None:\n            moutput = self.model (input_ids=input_ids, attention_mask=attention_mask)\n            last_hidden_states = moutput[0]\n        else:\n            moutput = self.model (input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n            last_hidden_states = moutput[0]\n        #print('last_hidden_states.size=', last_hidden_states.size())\n        \n        # GAP: last_hidden_states shape = batch_size * max_seq_len * emb_dim(1024?)\n        # output shape = batch_size * emb_dim(1024?)  i.e avg across the sequence\n        last_hidden_states = torch.mean (last_hidden_states, 1)             #;print('GAP last_hidden_states.size=', last_hidden_states.size())\n        # fcnn\n        X = self.dense (last_hidden_states)\n        return X","metadata":{"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class TripletModel (nn.Module):\n    \n    def __init__(self, embeddingModel):\n        \n        super (TripletModel, self).__init__()\n        self.embeddingModel = embeddingModel\n    \n    def forward (self, i1, i2, i3):\n        \n        E1 = self.embeddingModel (**i1)\n        E2 = self.embeddingModel (**i2)\n        E3 = self.embeddingModel (**i3)\n        return E1, E2, E3\n    \n    def freeze (self):\n        self.embeddingModel.freeze ()\n        return\n    \n    def unfreeze (self):\n        self.embeddingModel.unfreeze ()\n        return","metadata":{"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model = MyGAPModelForSeqClf (bert_model_name)\n\n# optional to load this model pre trained on mnli\ntry:\n    model.load_state_dict (torch.load (\"../input/robertagapxnlimnlirishi/roberta-gap-xnli-mnli-rishi/my_model.bin\"))\nexcept:\n    model.load_state_dict (torch.load (\"../input/robertagapxnlimnlirishi/roberta-gap-xnli-mnli-rishi/my_model.bin\", map_location='cpu'))\n\nmodel = TripletModel (model)\n\nimport warnings\nwarnings.filterwarnings (\"ignore\")\nmodel.to (CFG.device)\nCFG.MODEL = model","metadata":{"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/2.24G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac5919b9acdc45b582aadc3c4130e10e"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Trainer Helpers","metadata":{"papermill":{"duration":0.052281,"end_time":"2021-03-29T06:13:09.38012","exception":false,"start_time":"2021-03-29T06:13:09.327839","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def format_time (elapsed):\n    '''\n    Takes a time in seconds and returns a string hh:mm:ss\n    '''\n    \n    # Round to the nearest second.\n    elapsed_rounded = int(round((elapsed)))\n    \n    # Format as hh:mm:ss\n    return str (datetime.timedelta (seconds=elapsed_rounded))","metadata":{"papermill":{"duration":0.059421,"end_time":"2021-03-29T06:13:09.49086","exception":false,"start_time":"2021-03-29T06:13:09.431439","status":"completed"},"tags":[],"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Trainer","metadata":{"papermill":{"duration":0.050869,"end_time":"2021-03-29T06:13:09.718636","exception":false,"start_time":"2021-03-29T06:13:09.667767","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class MyTrainer:\n    \n    def __init__(self, fold, model, train_dataset, eval_dataset, criterion, \n                 checkpoint_path=None, isResume=False):\n        \n        self.fold             = fold\n        self.start_epoch      = 0\n        self.model            = model\n        # load checkpoint\n        if checkpoint_path is not None:\n            if isResume:\n                self.start_epoch = self.load_checkpoint (checkpoint_path, isResume=True) + 1\n            else:\n                self.load_checkpoint (checkpoint_path, isResume=False)\n        self.model            = self.model.to (CFG.device)\n        if CFG.isFreeze:\n            self.model.freeze ()\n        else:\n            self.model.unfreeze ()\n        CFG.MODEL             = self.model\n        self.train_dataset    = train_dataset\n        self.eval_dataset     = eval_dataset\n        self.criterion        = criterion\n        self.isTrained        = False\n        self.device           = CFG.device\n        self.optimizer        = AdamW (self.model.parameters (), lr=CFG.lr, eps=CFG.adam_epsilon, weight_decay=CFG.weight_decay)\n        self.epochs           = CFG.epochs\n        self.set_dataLoaders ()\n        self.training_stats   = []\n        self.modelFile        = f\"{CFG.model_train_path_prefix}/{CFG.model_name}_{CFG.size}_fold{self.fold}.pth\"\n        if eval_dataset is not None:\n            self.minLossModelFile = f\"{CFG.model_train_path_prefix}/{CFG.model_name}_{CFG.size}_fold{self.fold}_min_val_loss.pth\"\n            self.maxAccModelFile  = f\"{CFG.model_train_path_prefix}/{CFG.model_name}_{CFG.size}_fold{self.fold}_max_val_acc.pth\"\n        else:\n            self.minLossModelFile = f\"{CFG.model_train_path_prefix}/{CFG.model_name}_{CFG.size}_fold{self.fold}_min_tr_loss.pth\"\n            self.maxAccModelFile  = f\"{CFG.model_train_path_prefix}/{CFG.model_name}_{CFG.size}_fold{self.fold}_max_tr_acc.pth\"\n        \n        self.min_val_loss         = 9999\n        self.min_train_loss       = 9999\n        self.max_val_acc          = -1    \n        return\n    \n    def set_dataLoaders (self):\n        # Create the DataLoaders for our training and validation sets.\n        \n        if isinstance (self.train_dataset, torch.utils.data.IterableDataset):\n            train_sampler = None\n        else:\n            train_sampler = RandomSampler (self.train_dataset)           # Better use RandomSampler\n        train_dataloader  = DataLoader (\n                    self.train_dataset,                                  # The training samples.\n                    sampler     = train_sampler,                           \n                    batch_size  = CFG.train_batch_size,\n                    num_workers = CFG.num_workers,\n                    pin_memory  = True\n        )\n        # train_dataloader  = DataLoader (self.train_dataset, batch_size=CFG.train_batch_size) # TODO: comment this\n        validation_dataloader = None\n        if self.eval_dataset:\n            validation_dataloader = DataLoader (\n                        self.eval_dataset, \n                        sampler     = SequentialSampler (self.eval_dataset),\n                        batch_size  = CFG.eval_batch_size,\n                        num_workers = CFG.num_workers,\n                        pin_memory  = False\n            )\n            # validation_dataloader  = DataLoader (self.eval_dataset, batch_size=CFG.eval_batch_size) # TODO: comment this\n        \n        if type (CFG.warmup_steps) is float:\n            CFG.warmup_steps = int (CFG.warmup_steps * len (train_dataloader))\n        # Total number of training steps is [number of batches] x [number of epochs]\n        num_training_steps = len (train_dataloader) * self.epochs        \n        lr_scheduler = get_cosine_schedule_with_warmup (self.optimizer, num_cycles=CFG.lr_num_cycles,\n                        num_warmup_steps=CFG.warmup_steps, num_training_steps=num_training_steps)\n        \n        if type (CFG.eval_steps) is float:\n            CFG.eval_steps = int (CFG.eval_steps * len (train_dataloader))\n        self.train_dataloader, self.validation_dataloader, self.lr_scheduler, self.num_training_steps=train_dataloader, validation_dataloader, lr_scheduler, num_training_steps\n        return\n            \n    def test_iterate_dataloader (self):\n        \n        for step, batch in enumerate (self.train_dataloader):\n            print (step)\n            print (batch)\n            break\n        return\n    \n    def save_checkpoint (self, epoch, path):\n        \n        checkpoint = {\n            'epoch'               : epoch,\n            'model_state_dict'    : self.model.state_dict (),\n            'optimizer_state_dict': self.optimizer.state_dict (),\n            'lr_sched_state_dict' : self.lr_scheduler.state_dict (),\n            'training_stats'      : self.training_stats,\n            'max_val_acc'         : self.max_val_acc,\n            'min_train_loss'      : self.min_train_loss,\n            'min_val_loss'        : self.min_val_loss,\n        }\n        torch.save (checkpoint, path)\n        gc.collect (); torch.cuda.empty_cache ()\n        print (\"saved checkpoint\", path)\n        return\n    \n    def load_checkpoint (self, path, isResume=False):\n        \n        epoch      = 0\n        checkpoint = torch.load (path, map_location=torch.device ('cpu'))\n        self.model.load_state_dict (checkpoint['model_state_dict'])\n        if isResume:\n            \n            self.optimizer.load_state_dict (checkpoint['optimizer_state_dict'])\n            self.lr_scheduler.load_state_dict (checkpoint['lr_sched_state_dict'])\n            epoch = checkpoint['epoch']\n            self.training_stats  = checkpoint['training_stats']\n            self.min_val_loss    = checkpoint['min_val_loss']\n            self.min_train_loss  = checkpoint['min_train_loss']\n            self.max_val_acc     = checkpoint['max_val_acc']\n            print (\"Loaded model, optimizer, and lr_scheduler from -\", path)\n        else:\n            print (\"Loaded model from -\", path)\n            \n        self.model.train ()\n        return epoch\n    \n    def train (self):\n        \n        seed_everything (seed=CFG.seed)\n        step             = 0\n        total_t0         = time.time ()\n        scaler           = GradScaler()\n        for epoch_i in range (self.start_epoch, self.epochs):\n            \n            avg_epoch_train_loss   = 0\n            total_epoch_train_loss = 0\n            print('======== Epoch {:} / {:} ========'.format (epoch_i + 1, self.epochs))\n            t0 = time.time ()\n            self.model.train ()\n            for stp, batch in tqdm (enumerate (self.train_dataloader), total=len(self.train_dataloader)):\n                \n                # Print Stats\n                # if step % CFG.print_every == 0:\n                #     elapsed = format_time (time.time() - t0)\n                #     print ('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format (step, len (self.train_dataloader), elapsed))                \n                if ((CFG.max_steps > 0 and CFG.max_steps < step) or \n                    (CFG.eval_steps>0 and stp==CFG.eval_steps)): # or step==0):   # TODO: rm this comment\n                    \n                    self.save_checkpoint (epoch_i, self.modelFile)\n                    training_time = format_time (time.time () - t0)            \n                    if self.validation_dataloader:\n                        \n                        avg_val_loss, avg_val_accuracy, validation_time = self.evaluate (epoch_i, avg_epoch_train_loss, training_time)\n                        # save this model if the eval loss decreases from the minimum so far\n                        checkpoint_epoch = epoch_i\n                        if stp==CFG.eval_steps:\n                            # don't count this epoch in the checkpoint since this epoch \n                            # has not completed. Hence, checkpoint at prev epoch\n                            checkpoint_epoch = epoch_i-1\n                        if avg_val_loss < self.min_val_loss:                             \n                            self.min_val_loss = avg_val_loss\n                            self.save_checkpoint (checkpoint_epoch, self.minLossModelFile)\n                        if avg_val_accuracy > self.max_val_acc:\n                            self.max_val_acc = avg_val_accuracy\n                            self.save_checkpoint (checkpoint_epoch, self.maxAccModelFile)\n                    if CFG.max_steps > 0 and CFG.max_steps < step:\n                        \n                        print (\"\")\n                        print (\"Training complete!\")\n                        print (\"Total training took {:} (h:mm:ss)\".format (format_time (time.time ()-total_t0)))\n                        self.isTrained = True\n                        self.model.cpu ()\n                        self.model.eval ()\n                        self.save_checkpoint (epoch_i, self.modelFile)\n                        try:\n                            torch.cuda.empty_cache ()\n                            self.plot_train_stats (self.training_stats)\n                        except:\n                            pass\n                        return pd.DataFrame (self.training_stats)\n                \n                ########################################################\n                # Train\n                ########################################################\n                # self.model.zero_grad ()\n                for i in [0,1,2]:\n                    for k in batch[i]:\n                        batch[i][k] = batch[i][k].to (self.device)\n                \n                anc_imgs = batch[0]\n                pos_imgs = batch[1]\n                neg_imgs = batch[2]\n                with autocast():\n                    \n                    E1, E2, E3 = self.model (anc_imgs, pos_imgs, neg_imgs)\n                    dist_E1_E2 = F.pairwise_distance (E1, E2, 2)\n                    dist_E1_E3 = F.pairwise_distance (E1, E3, 2)\n                    target = torch.FloatTensor (dist_E1_E2.size()).fill_ (-1)\n                    target = target.to (CFG.device)\n                    loss = self.criterion (dist_E1_E2, dist_E1_E3, target)\n                    scaler.scale (loss).backward ()\n                    # torch.nn.utils.clip_grad_norm_ (self.model.parameters (), CFG.max_grad_norm)\n                    scaler.step (self.optimizer)\n                    scaler.update ()\n                    self.optimizer.zero_grad ()\n                    self.lr_scheduler.step ()\n                    \n                total_epoch_train_loss += loss.cpu ().item ()\n                avg_epoch_train_loss    = total_epoch_train_loss / (stp+1)\n                step += 1\n            # all steps of an epoch end\n            \n            # Measure how long this epoch took.\n            training_time = format_time (time.time () - t0)            \n            print (\"  Average training loss: {0:.4f}\".format (avg_epoch_train_loss))\n            print (\"  Training epcoh took: {:}\".format (training_time))            \n            if self.validation_dataloader:    \n                \n                avg_val_loss, avg_val_accuracy, validation_time = self.evaluate (epoch_i, avg_epoch_train_loss, training_time)\n                # save this epoch's model if the eval loss decreases from the minimum so far\n                if avg_val_loss < self.min_val_loss:                    \n                    self.min_val_loss = avg_val_loss\n                    self.save_checkpoint (epoch_i, self.minLossModelFile)\n                if avg_val_accuracy > self.max_val_acc:\n                    self.max_val_acc = avg_val_accuracy\n                    self.save_checkpoint (epoch_i, self.maxAccModelFile)\n            else:                \n                training_stats.append ({\n                    'epoch'         : epoch_i + 1,\n                    'training_loss' : avg_epoch_train_loss,\n                    'training_time' : training_time,\n                })\n                if avg_train_loss < self.min_train_loss:                     \n                    self.min_train_loss = avg_train_loss\n                    self.save_checkpoint (epoch_i, self.minLossModelFile)\n            self.save_checkpoint (epoch_i, self.modelFile)\n            # 1 epoch end\n        # all epochs end\n        \n        # just get the best class thresholds at the end\n        if self.validation_dataloader:\n            print ('At training end, threshold Adjustment (last row of the train summary DF)')\n            print (self.evaluate (epoch_i, avg_epoch_train_loss, training_time, isThreshAdjust=True))\n            print ('<: avg_val_loss, avg_val_accuracy, validation_time')\n        \n        print (\"***** Training complete! *****\")\n        print (\"Total training took {:} (h:mm:ss)\".format (format_time (time.time ()-total_t0)))\n        self.isTrained = True\n        self.model.cpu ()\n        self.model.eval ()\n        try:\n            torch.cuda.empty_cache ()\n            self.plot_train_stats (self.training_stats)\n        except:\n            pass\n        return pd.DataFrame (self.training_stats)\n    \n    def evaluate (self, epoch_i, avg_train_loss=999, training_time=999, isThreshAdjust=False):\n        \n        t0           = time.time ()\n        all_labels   = []\n        all_pred_prs = []\n        # Put the model in evaluation mode--the dropout layers behave differently\n        # during evaluation.\n        self.model.eval ()\n        \n        # Tracking variables\n        total_eval_accuracy  = 0\n        total_eval_loss      = 0\n        nb_eval_steps        = 0\n        correct_pred_count   = 0\n        total_pred_count     = 0\n        # Evaluate data for one epoch\n        for batch in self.validation_dataloader:\n            with torch.no_grad ():\n                \n                for i in [0,1,2]:\n                    for k in batch[i]:\n                        batch[i][k] = batch[i][k].to (self.device)\n                \n                anc_imgs = batch[0]\n                pos_imgs = batch[1]\n                neg_imgs = batch[2]            \n                E1, E2, E3 = self.model (anc_imgs, pos_imgs, neg_imgs)\n                dist_E1_E2 = F.pairwise_distance (E1, E2, 2)\n                dist_E1_E3 = F.pairwise_distance (E1, E3, 2)\n                target     = torch.FloatTensor (dist_E1_E2.size()).fill_ (-1).to (CFG.device)\n                loss       = self.criterion (dist_E1_E2, dist_E1_E3, target).cpu ().detach ()\n            \n            correct_pred_count += sum ((dist_E1_E2 < dist_E1_E3) + 0.0)\n            total_pred_count   += len (dist_E1_E2) \n            total_eval_loss    += loss.item ()     \n        \n        avg_val_loss     = total_eval_loss / len (self.validation_dataloader)\n        avg_val_accuracy = correct_pred_count / total_pred_count\n        print (\"Val Loss: {0:.4f}\".format (avg_val_loss))\n        print (\"Val Accuracy: {0:.4f}\".format (avg_val_accuracy))\n        validation_time = format_time (time.time () - t0)\n        self.training_stats.append ({\n                'epoch'         : epoch_i + 1,\n                'training_loss' : avg_train_loss,\n                'eval_loss'     : avg_val_loss,\n                'eval_accuracy' : avg_val_accuracy,\n                'training_time' : training_time,\n                'eval_time'     : validation_time                   \n        })\n        self.model.train ()\n        print (\"Validation took {:} (h:mm:ss)\".format (format_time (time.time () - t0)))\n        return avg_val_loss, avg_val_accuracy, validation_time\n        \n        \n    def plot_train_stats (self, training_stats):\n        \"\"\"\n        Draw Classification Report curve\n        \"\"\"\n        \n        accuracies = eval_losses = tr_losses = epochs = -1\n        epochs = len (training_stats)\n        if 'eval_accuracy' in training_stats[0]:\n            accuracies = [e['eval_accuracy'] for e in training_stats]\n            sns.lineplot (x=np.arange(1, epochs + 1), y=accuracies, label='val_accuracy')\n        if 'eval_loss' in training_stats[0]:\n            eval_losses= [e['eval_loss'] for e in training_stats]\n        if 'training_loss'  in training_stats[0]:\n            tr_losses  = [e['training_loss'] for e in training_stats]\n            sns.lineplot (x=np.arange(1, epochs + 1), y=tr_losses,  label='tr_losses')\n            \n        plt.show ()\n        print ('accuracies :', accuracies)        \n        print ('eval_losses:', eval_losses)\n        print ('tr_losses  :', tr_losses)\n        return\n    \n    def get_trained_model (self):\n        \n        if self.isTrained:\n            return self.model.eval ()\n        return None","metadata":{"papermill":{"duration":0.126789,"end_time":"2021-03-29T06:13:09.896626","exception":false,"start_time":"2021-03-29T06:13:09.769837","status":"completed"},"tags":[],"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def free_gpu_cache ():\n    \n    # print(\"Initial GPU Usage\")\n    # gpu_usage()                             \n\n    torch.cuda.empty_cache()\n\n    # cuda.select_device(0)\n    # cuda.close()\n    # cuda.select_device(0)\n\n    # print(\"GPU Usage after emptying the cache\")\n    # gpu_usage()\n    return\n\n# free_gpu_cache()           ","metadata":{"papermill":{"duration":0.065307,"end_time":"2021-03-29T06:13:10.015641","exception":false,"start_time":"2021-03-29T06:13:09.950334","status":"completed"},"tags":[],"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Train","metadata":{"papermill":{"duration":0.051834,"end_time":"2021-03-29T06:13:10.119642","exception":false,"start_time":"2021-03-29T06:13:10.067808","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def train_fold_loop (checkpoint_path=None):\n\n    print (f\"========== training ==========\")\n    fold = 0 # fold is not used\n    criterion      = get_criterion (CFG.margin)\n    model          = CFG.MODEL\n    if model is None and checkpoint_path is None:\n        print (\"CFG.MODEL is None\")\n        model      = getModel (fold, isTrain=True)\n        model      = model.float()\n    elif model is not None and checkpoint_path is not None:\n        pass\n        # checkpoint_path = None\n    elif model is None and checkpoint_path is not None:\n        print (\"CFG.MODEL is None\")\n        model      = getModel (fold, isTrain=False)\n        model      = model.float()\n        \n    train_dataset  = TripletTextDataset ()\n    valid_dataset  = TripletTextDataset (TEST_DF)\n    trainer        = MyTrainer (\n        fold            = fold,\n        model           = model,\n        train_dataset   = train_dataset,\n        eval_dataset    = valid_dataset,\n        criterion       = criterion,\n        checkpoint_path = checkpoint_path\n    )\n    metrics = trainer.train ()\n    return metrics\n    \n    # To plot lr uncomment this\n    # lrs = []\n    # for i in range (CFG.epochs*len (trainer.train_dataloader)):\n    #     trainer.lr_scheduler.step ()\n    #     lrs.append (trainer.optimizer.param_groups[0][\"lr\"])\n    # print (lrs)\n    # plt.plot (lrs)\n    # plt.show ()","metadata":{"papermill":{"duration":0.069432,"end_time":"2021-03-29T06:13:10.24463","exception":false,"start_time":"2021-03-29T06:13:10.175198","status":"completed"},"tags":[],"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def train_main (checkpoint_path=None):\n    \n    # print (f\"========== train_main() ==========\")\n    if CFG.isTrain:        \n        valid_scores_df = pd.DataFrame ()\n        for fold in range (CFG.n_fold):\n            if fold in CFG.train_fold:\n                \n                valid_scores_fold_df = train_fold_loop (checkpoint_path)\n                # valid_scores_fold = np.array (valid_scores_fold).reshape ((1, -1))\n                valid_scores_df = valid_scores_df.append (valid_scores_fold_df)\n                \n        print (f\"========== CV ==========\")\n        # print (valid_scores_df)\n        # valid_scores = np.vstack (valid_scores)\n        # valid_scores = np.mean (valid_scores, axis=0)\n        valid_scores = valid_scores_df.iloc[-1, :]  #.mean ()\n        print (\"CV Scores :-\");  print (valid_scores)\n    return valid_scores_df","metadata":{"papermill":{"duration":0.061261,"end_time":"2021-03-29T06:13:10.357409","exception":false,"start_time":"2021-03-29T06:13:10.296148","status":"completed"},"tags":[],"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Single config training","metadata":{"papermill":{"duration":0.050971,"end_time":"2021-03-29T06:13:10.459841","exception":false,"start_time":"2021-03-29T06:13:10.40887","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"!mkdir -p /kaggle/working/Output/\n!touch /kaggle/working/Output/train.log\ngc.collect ()\nmodel_names = timm.list_models (pretrained=True)\nmodel_names = timm.list_models ('*resnet*', pretrained=True)\npprint (model_names)\nLOGGER = init_logger ()\nseed_everything (seed=CFG.seed)","metadata":{"papermill":{"duration":0.051612,"end_time":"2021-03-29T06:13:10.563247","exception":false,"start_time":"2021-03-29T06:13:10.511635","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"valid_scores_df = train_main ()\n\nvalid_scores_df","metadata":{"papermill":{"duration":0.051001,"end_time":"2021-03-29T06:13:10.665748","exception":false,"start_time":"2021-03-29T06:13:10.614747","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# To train, uncomment these","metadata":{"papermill":{"duration":0.052916,"end_time":"2021-03-29T06:13:10.770432","exception":false,"start_time":"2021-03-29T06:13:10.717516","status":"completed"},"tags":[]}},{"cell_type":"code","source":"gc.collect (); torch.cuda.empty_cache ()\nCFG.warmup_steps = 0.5\nCFG.eval_steps   = 0.5\nCFG.num_workers  = 8\nCFG.train_batch_size = 16\nCFG.eval_batch_size  = 16\nCFG.freeze = True\nCFG.epochs = 4\nprint (f\"***** Training, freeze={CFG.isFreeze} *****\")\nvalid_scores_df = train_main () \nvalid_scores_df","metadata":{"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"***** Training, freeze=True *****\n========== training ==========\n======== Epoch 1 / 4 ========\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/1927 [00:00<?, ?it/s]","output_type":"stream"}]},{"cell_type":"code","source":"gc.collect (); torch.cuda.empty_cache ()\nCFG.warmup_steps = 0.5\nCFG.eval_steps   = 0.5\nCFG.num_workers = 8\nCFG.train_batch_size = 1\nCFG.eval_batch_size  = 1\nCFG.isFreeze = False\nCFG.epochs = 2\nprint (f\"***** Training, freeze={CFG.isFreeze} *****\")\nvalid_scores_df = train_main (\"../input/shopee-pytorch-siamese-triplet-loss-xlmroberta/xlmroberta_128_fold0.pth\")\nvalid_scores_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print ('Done !')","metadata":{"papermill":{"duration":0.109165,"end_time":"2021-03-29T06:13:39.505776","exception":false,"start_time":"2021-03-29T06:13:39.396611","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}